{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        # Lending Club Exploratory Data Analysis Case Study\n",
    "                            By Gopinath Moganasundaram and Mir Riaz Ahmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "The data set given (loan.csv) contains information about past loan applicants and whether they ‘defaulted’ or not. The aim is to analyze the data and identify patterns which indicate if a person is likely to default, which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc.\n",
    " \n",
    "In this case study, we will use EDA to understand how consumer attributes and loan attributes influence the tendency of default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "The approach is to load the data, clean it up, perform EDA concepts on the data and then derive conclusion/recommendations on the driving factors behind loan defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39717, 111)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "loan_df = pd.read_csv('loan.csv')\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "      <th>total_il_high_credit_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501    1296599       5000         5000           4975.0   36 months   \n",
       "1  1077430    1314167       2500         2500           2500.0   60 months   \n",
       "2  1077175    1313524       2400         2400           2400.0   36 months   \n",
       "3  1076863    1277178      10000        10000          10000.0   36 months   \n",
       "4  1075358    1311748       3000         3000           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade  ... num_tl_90g_dpd_24m  \\\n",
       "0   10.65%       162.87     B        B2  ...                NaN   \n",
       "1   15.27%        59.83     C        C4  ...                NaN   \n",
       "2   15.96%        84.33     C        C5  ...                NaN   \n",
       "3   13.49%       339.31     C        C1  ...                NaN   \n",
       "4   12.69%        67.79     B        B5  ...                NaN   \n",
       "\n",
       "  num_tl_op_past_12m pct_tl_nvr_dlq  percent_bc_gt_75 pub_rec_bankruptcies  \\\n",
       "0                NaN            NaN               NaN                  0.0   \n",
       "1                NaN            NaN               NaN                  0.0   \n",
       "2                NaN            NaN               NaN                  0.0   \n",
       "3                NaN            NaN               NaN                  0.0   \n",
       "4                NaN            NaN               NaN                  0.0   \n",
       "\n",
       "  tax_liens tot_hi_cred_lim total_bal_ex_mort total_bc_limit  \\\n",
       "0       0.0             NaN               NaN            NaN   \n",
       "1       0.0             NaN               NaN            NaN   \n",
       "2       0.0             NaN               NaN            NaN   \n",
       "3       0.0             NaN               NaN            NaN   \n",
       "4       0.0             NaN               NaN            NaN   \n",
       "\n",
       "  total_il_high_credit_limit  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check top 5 rows to understand columns and the kind of data that is present\n",
    "loan_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing null columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove columns which have all nulls\n",
    "Using shape, we found that there are total 39717 rows.\n",
    "Checking nulls shows that there are a lot of columns who have nulls in all the rows.\n",
    "We can remove those columns from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_rev_hi_lim              39717\n",
       "inq_fi                        39717\n",
       "total_cu_tl                   39717\n",
       "inq_last_12m                  39717\n",
       "acc_open_past_24mths          39717\n",
       "avg_cur_bal                   39717\n",
       "bc_open_to_buy                39717\n",
       "bc_util                       39717\n",
       "mo_sin_old_rev_tl_op          39717\n",
       "total_il_high_credit_limit    39717\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get \n",
    "loan_df.isnull().sum().sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39717, 57)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop null columns and then check the shape\n",
    "loan_df = loan_df.dropna(axis=1, how='all')\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns which have more than 40% of nulls\n",
    "Now that we are left with only 57 columns, lets check the null percentage of columns and remove columns with more than 40% nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections_12_mths_ex_med    0.001410\n",
       "chargeoff_within_12_mths      0.001410\n",
       "last_pymnt_d                  0.001788\n",
       "pub_rec_bankruptcies          0.017549\n",
       "emp_length                    0.027066\n",
       "emp_title                     0.061913\n",
       "desc                          0.325805\n",
       "mths_since_last_delinq        0.646625\n",
       "mths_since_last_record        0.929854\n",
       "next_pymnt_d                  0.971297\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking mean on isnull for all columns\n",
    "loan_df.isnull().mean().sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39717, 54)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing columns mths_since_last_delinq, mths_since_last_record, next_pymnt_d\n",
    "loan_df = loan_df.drop(['mths_since_last_delinq', 'mths_since_last_record', 'next_pymnt_d'], axis=1)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "member_id                0.000000\n",
       "home_ownership           0.000000\n",
       "last_credit_pull_d       0.005036\n",
       "title                    0.027696\n",
       "revol_util               0.125891\n",
       "last_pymnt_d             0.178765\n",
       "pub_rec_bankruptcies     1.754916\n",
       "emp_length               2.706650\n",
       "emp_title                6.191303\n",
       "desc                    32.580507\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking mean on isna for all column\n",
    "loan_df.isna().mean().sort_values().tail(10)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39717, 44)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing column 'desc'\n",
    "loan_df = loan_df.drop('desc', axis=1)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns which have same values for all rows\n",
    "Let's figure out those columns with nunique and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tax_liens                     1\n",
       "delinq_amnt                   1\n",
       "chargeoff_within_12_mths      1\n",
       "acc_now_delinq                1\n",
       "application_type              1\n",
       "policy_code                   1\n",
       "initial_list_status           1\n",
       "collections_12_mths_ex_med    1\n",
       "pymnt_plan                    1\n",
       "term                          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.nunique().sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39717, 45)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df = loan_df.drop(['tax_liens', 'delinq_amnt', 'chargeoff_within_12_mths', 'acc_now_delinq', 'application_type'], axis=1)\n",
    "loan_df = loan_df.drop(['policy_code', 'initial_list_status', 'collections_12_mths_ex_med', 'pymnt_plan'], axis=1)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove irrelevant columns\n",
    "Now let's figure out columns that are not relevant to our analysis and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
       "       'emp_length', 'home_ownership', 'annual_inc', 'verification_status',\n",
       "       'issue_d', 'loan_status', 'url', 'desc', 'purpose', 'title', 'zip_code',\n",
       "       'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',\n",
       "       'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util',\n",
       "       'total_acc', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
       "       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
       "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
       "       'last_pymnt_d', 'last_pymnt_amnt', 'last_credit_pull_d',\n",
       "       'pub_rec_bankruptcies'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'member_id', 'desc', 'title']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The id columns are not needed for analysis\n",
    "irrelevant_columns = ['id', 'member_id']\n",
    "\n",
    "# Other irrelevant columns\n",
    "irrelevant_columns.append('url')\n",
    "irrelevant_columns.append('title')\n",
    "irrelevant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "member_id               0.000000\n",
       "home_ownership          0.000000\n",
       "last_credit_pull_d      0.000050\n",
       "title                   0.000277\n",
       "revol_util              0.001259\n",
       "last_pymnt_d            0.001788\n",
       "pub_rec_bankruptcies    0.017549\n",
       "emp_length              0.027066\n",
       "emp_title               0.061913\n",
       "desc                    0.325805\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df['dti'].value_counts()\n",
    "loan_df.shape\n",
    "\n",
    "loan_df.isnull().mean().sort_values().tail(10)\n",
    "loan_df.isna().mean().sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows:  (0, 45)\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any duplicate rows and remove them\n",
    "print(\"Duplicate rows: \", loan_df[loan_df.duplicated()].shape)\n",
    "# No duplicate rows found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove records where status = 'Current'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = loan_df[loan_df.loan_status != \"Current\"]\n",
    "loan_df.loan_status.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct the data type of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.revol_util = pd.to_numeric(loan_data.revol_util.apply(lambda x : x.split('%')[0]))\n",
    "loan_data.int_rate = pd.to_numeric(loan_data.int_rate.apply(lambda x : x.split('%')[0]))\n",
    "loan_data.emp_length = pd.to_numeric(loan_data.emp_length.apply(lambda x: 0 if \"<\" in x else (x.split('+')[0] if \"+\" in x else x.split()[0])))\n",
    "loan_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(loan_data['annual_inc'])\n",
    "-----\n",
    "quantile_info = loan_data.annual_inc.quantile([0.5, 0.75,0.90, 0.95, 0.97,0.98, 0.99])\n",
    "quantile_info\n",
    "-----\n",
    "per_95_annual_inc = loan_data['annual_inc'].quantile(0.95)\n",
    "loan_data = loan_data[loan_data.annual_inc <= per_95_annual_inc]\n",
    "------\n",
    "sns.boxplot(loan_data.annual_inc)\n",
    "-------\n",
    "sns.boxplot(loan_data.dti) # no outlier\n",
    "-------\n",
    "sns.boxplot(loan_data.loan_amnt)\n",
    "-------\n",
    "loan_data.loan_amnt.quantile([0.75,0.90,0.95,0.97,0.975, 0.98, 0.99, 1.0])\n",
    "-------\n",
    "sns.boxplot(loan_data.funded_amnt_inv)\n",
    "-------\n",
    "loan_data.funded_amnt_inv.quantile([0.5,0.75,0.90,0.95,0.97,0.975, 0.98,0.985, 0.99, 1.0])\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = 'loan_status', data = loan_data)\n",
    "-------\n",
    "loan_data.sub_grade = pd.to_numeric(loan_data.sub_grade.apply(lambda x : x[-1]))\n",
    "loan_data.sub_grade.head()\n",
    "-------\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "sns.set_palette('colorblind')\n",
    "sns.countplot(x = 'grade', order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'] , hue = 'sub_grade',data = loan_data[loan_data.loan_status == 'Charged Off'])\n",
    "-------\n",
    "sns.countplot(x = 'grade', data = loan_data[loan_data.loan_status == 'Charged Off'], order = ['A', 'B', 'C', 'D', 'E', 'F', 'G'])\n",
    "-------\n",
    "# Analyze home ownership\n",
    "#checking unique values for home_ownership\n",
    "loan_data['home_ownership'].unique()\n",
    "--------\n",
    "# There are only 3 values with 'NONE' so replacing with OTHER\n",
    "#replacing 'NONE' with 'OTHERS'\n",
    "loan_data['home_ownership'].replace(to_replace = ['NONE'],value='OTHER',inplace = True)\n",
    "--------\n",
    "#checking unique values for home_ownership again\n",
    "loan_data['home_ownership'].unique()\n",
    "---------\n",
    "fig, ax = plt.subplots(figsize = (6,4))\n",
    "ax.set(yscale = 'log')\n",
    "sns.countplot(x='home_ownership', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "---------\n",
    "# Analyzing purpose\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "ax.set(xscale = 'log')\n",
    "sns.countplot(y ='purpose', data=loan_data[loan_data.loan_status == 'Charged Off'])\n",
    "---------\n",
    "# Creating bins for numerical rows\n",
    "#creating bins for int_rate,open_acc,revol_util,total_acc\n",
    "loan_data['int_rate_groups'] = pd.cut(loan_data['int_rate'], bins=5,precision =0,labels=['5%-9%','9%-13%','13%-17%','17%-21%','21%-24%'])\n",
    "loan_data['open_acc_groups'] = pd.cut(loan_data['open_acc'],bins = 5,precision =0,labels=['2-10','10-19','19-27','27-36','36-44'])\n",
    "loan_data['revol_util_groups'] = pd.cut(loan_data['revol_util'], bins=5,precision =0,labels=['0-20','20-40','40-60','60-80','80-100'])\n",
    "loan_data['total_acc_groups'] = pd.cut(loan_data['total_acc'], bins=5,precision =0,labels=['2-20','20-37','37-55','55-74','74-90'])\n",
    "loan_data['annual_inc_groups'] = pd.cut(loan_data['annual_inc'], bins=5,precision =0,labels =['3k-31k','31k-58k','58k-85k','85k-112k','112k-140k'])\n",
    "---------\n",
    "    # Viewing new bins created\n",
    "    loan_data.head()\n",
    "---------\n",
    "# Analyzing interest rate wrt to interest rate bins\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "plt.subplot(221)\n",
    "sns.countplot(x='int_rate_groups', data=loan_data[loan_data.loan_status == 'Charged Off'])\n",
    "plt.xlabel('Interest Rate')\n",
    "plt.subplot(222)\n",
    "sns.countplot(x='emp_length', data=loan_data[loan_data.loan_status == 'Charged Off'])\n",
    "----------\n",
    "#### Similarly analyzing open_acc,revol_util,total_acc,annual_inc\n",
    "fig, ax = plt.subplots(figsize = (7,5))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='open_acc_groups', data=loan_data[loan_data.loan_status == 'Charged Off'])\n",
    "----------\n",
    "sns.countplot(x='revol_util_groups', data=loan_data[loan_data.loan_status == 'Charged Off'])\n",
    "---------\n",
    "fig, ax = plt.subplots(figsize = (8,6))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='total_acc_groups', data=loan_data[loan_data.loan_status == 'Charged Off'])\n",
    "----------\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "sns.countplot(x='annual_inc_groups', data=loan_data[loan_data.loan_status == 'Charged Off'])\n",
    "---------\n",
    "sns.countplot(y='term', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "---------\n",
    "sns.countplot(x='verification_status', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "---------\n",
    "fig,ax = plt.subplots(figsize = (10,8))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='inq_last_6mths', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "----------\n",
    "fig,ax = plt.subplots(figsize = (7,5))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='pub_rec', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "----------\n",
    "# Analyzing issue month and year\n",
    "## Extracting month and year\n",
    "df_month_year = loan_data['issue_d'].str.partition(\"-\", True)     \n",
    "loan_data['issue_month']=df_month_year[0]                       \n",
    "loan_data['issue_year']='20' + df_month_year[2]\n",
    "----------\n",
    "loan_data.head()\n",
    "----------\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(221)\n",
    "sns.countplot(x='issue_month', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "plt.subplot(222)\n",
    "sns.countplot(x='issue_year', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Maximum number of defaults occured when the loan was sanctioned/issued in Dec. Loan issued in the year 2011 were also as compared to other years\n",
    "\n",
    "### Analyzing installment,dti, loan_amnt \n",
    "-----------\n",
    "loan_data['installment_groups'] = pd.cut(loan_data['installment'], bins=10,precision =0,labels=['14-145','145-274','274-403','403-531','531-660','660-789','789-918','918-1047','1047-1176','1176-1305'])\n",
    "loan_data['funded_amnt_inv_group'] = pd.cut(loan_data['funded_amnt_inv'], bins=7,labels=['0-5k','5k-10k','10k-15k','15k-20k','20k-25k','25k-30k','30k-35k']) ## bin is starting from -35?\n",
    "loan_data['loan_amnt_groups'] = pd.cut(loan_data['loan_amnt'], bins=7,precision =0,labels=['0-5k','5k-10k','10k-15k','15k-20k','20k-25k','25k-30k','30k-35k'])\n",
    "loan_data['dti_groups'] = pd.cut(loan_data['dti'], bins=5,precision =0,labels=['0-6','6-12','12-18','18-24','24-30'])\n",
    "----------\n",
    "fig,ax = plt.subplots(figsize = (12,5))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='funded_amnt_inv_group', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "---------\n",
    "fig,ax = plt.subplots(figsize = (12,5))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='funded_amnt_inv_group', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "----------\n",
    "sns.countplot(x='dti_groups', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "----------\n",
    "fig,ax = plt.subplots(figsize = (15,6))\n",
    "ax.set_yscale('log')\n",
    "sns.countplot(x='installment_groups', data=loan_data[loan_data['loan_status']=='Charged Off'])\n",
    "----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations\n",
    "\n",
    "### The above analysis with respect to the charged off loans for each variable suggests the following. There is a more probability of defaulting when : \n",
    "\n",
    "- Applicants having house_ownership as 'RENT'\n",
    "- Applicants who use the loan to clear other debts\n",
    "- Applicants who receive interest at the rate of 13-17%\n",
    "- Applicants who have an income of range 31201 - 58402\n",
    "- Applicants who have 20-37 open_acc\n",
    "- Applicants with employement length of 10\n",
    "- When funded amount by investor is between 5000-10000\n",
    "- Loan amount is between 5429 - 10357\n",
    "- Dti is between 12-18\n",
    "- When monthly installments are between 145-274\n",
    "- Term of 36 months\n",
    "- When the loan status is Not verified\n",
    "- When the no of enquiries in last 6 months is 0\n",
    "- When the number of derogatory public records is 0\n",
    "- When the purpose is 'debt_consolidation'\n",
    "- Grade is 'B'\n",
    "- And a total grade of 'B5' level.\n",
    "-----------------------------------------------------\n",
    "### Also there is a very interesting observation from the date issued. The late months of an year indicated the high possibility of defaulting. \n",
    "- The high number of loan defaults in 2011 could be due to the financial crisis in USA (Assuming the data is of US origin)\n",
    "--------------------------------------\n",
    "## Analysing annual income with other columns for more insights \n",
    "------------\n",
    "Annucal income vs loan purpose\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_data,x='annual_inc', y='purpose', hue ='loan_status',palette=\"deep\")\n",
    "plt.show()\n",
    "-------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Though the number of loans applied and defaulted are the highest in number for \"debt_consolation\", the annual income of those who applied isn't the highest. \n",
    "- Applicants with higher salary mostly applied loans for \"home_improvment\", \"house\", \"renewable_energy\" and \"small_businesses\"\n",
    "#### 2.Annual income vs home ownership\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_data,x='home_ownership', y='annual_inc', hue ='loan_status',palette=\"pastel\")\n",
    "plt.show()\n",
    "##### Annual income vs loan amout\n",
    "sns.barplot(x = \"annual_inc_groups\", y = \"loan_amnt\", hue = 'loan_status', data = loan_data)\n",
    "#### Annaul Income vs Interest rate \n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_data,x='int_rate_groups', y='annual_inc', hue ='loan_status',palette=\"pastel\")\n",
    "plt.show()\n",
    "-----------------\n",
    "#### Loan vs Loan purpose\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_data,x='loan_amnt', y='purpose', hue ='loan_status',palette=\"pastel\")\n",
    "plt.show()\n",
    "#### Loan vs house ownership\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_data,x='loan_amnt', y='home_ownership', hue ='loan_status',palette=\"pastel\")\n",
    "plt.show()\n",
    "#### Loan amount vs month issues and year issued\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(221)\n",
    "sns.lineplot(data =loan_data,y='loan_amnt', x='issue_month', hue ='loan_status',palette=\"pastel\")\n",
    "plt.subplot(222)\n",
    "sns.lineplot(data =loan_data,y='loan_amnt', x='issue_year', hue ='loan_status',palette=\"pastel\")\n",
    "#### Loan amount vs grade\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_data,x='loan_amnt', y='grade', hue ='loan_status',palette=\"pastel\", order=['A','B','C','D','E','F','G'])\n",
    "plt.show()\n",
    "-----------------------\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(221)\n",
    "sns.barplot(data =loan_data,y='loan_amnt', x='emp_length', hue ='loan_status',palette=\"pastel\")\n",
    "plt.subplot(222)\n",
    "sns.barplot(data =loan_data,y='loan_amnt', x='verification_status', hue ='loan_status',palette=\"pastel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Employees with longer working history got the loan approved for a higher amount. \n",
    "- Looking at the verification status data, verified loan applications tend to have higher loan amount. Which might indicate that the firms are first verifying the loans with higher values.\n",
    "------\n",
    "# Grade vs Interest rate\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.barplot(data =loan_data,x='int_rate', y='grade', hue ='loan_status',palette=\"pastel\", order=['A','B','C','D','E','F','G'])\n",
    "plt.show()\n",
    "-----------------\n",
    "# fig,ax = plt.subplots(figsize = (15,6))\n",
    "plt.tight_layout()\n",
    "sns.catplot(data =loan_data,y ='int_rate', x ='loan_amnt_groups', hue ='loan_status',palette=\"pastel\",kind = 'box')\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The interest rate for charged off loans is pretty high than that of fully paid loans in all the loan_amount groups. \n",
    "# - This can be a pretty strong driving factor for loan defaulting.\n",
    "sns.catplot(x = 'term', y = 'loan_amnt', data = loan_data,hue = 'loan_status', kind = 'bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applicants who applied and defaulted have no significant difference in loan_amounts.\n",
    "- Which means that applicants applying for long term has applied for more loan. \n",
    "\n",
    "# Observations\n",
    "\n",
    "### The above analysis with respect to the charged off loans. There is a more probability of defaulting when : \n",
    "\n",
    "- Applicants taking loan for 'home improvement' and have income of 60k -70k\n",
    "- Applicants whose home ownership is 'MORTGAGE and have income of 60-70k\n",
    "- Applicants who receive interest at the rate of 21-24% and have an income of 70k-80k\n",
    "- Applicants who have taken a loan in the range 30k - 35k and are charged interest rate of 15-17.5 %\n",
    "- Applicants who have taken a loan for small business and the loan amount is greater than 14k\n",
    "- Applicants whose home ownership is 'MORTGAGE and have loan of 14-16k\n",
    "- When grade is F and loan amount is between 15k-20k\n",
    "- When employment length is 10yrs and loan amount is 12k-14k \n",
    "- When the loan is verified and loan amount is above 16k\n",
    "- For grade G and interest rate above 20%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
